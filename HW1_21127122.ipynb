{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "\n",
    "\n",
    "Hồ Thanh Nhân - 21127122\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. \n",
    "(i) Not learning. There is no learning or adaptation involved. The coin classification system is created by the developers. Obtaining exact coin specifications from the U.S. Mint.\n",
    "\n",
    "(ii) Supervised Learning. There is an algorithm which uses a large set of labeled coins to find out the boundaries for classifying coins.\n",
    "\n",
    "(iii) Reinforcement Learning. Because the computer develops a strategy repeatly and adjusting its strategy at each move to lead to the losing.\n",
    "\n",
    "Therefore, the answer is: [d] (i) Not learning, (ii) Supervised Learning, (iii) Reinforcement Learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\n",
    "(i) Classifying numbers into primes and non-primes: This problem can be solved without using Machine Learning. It can be solved by using a simple algorithm which can determine whether a number is prime or not.\n",
    "\n",
    "(ii) Detecting potential fraud in credit card charges: This problem is the best suited for Machine Learning. It can be solved by using Supervised Learning type of Machine Learning to train the historical transaction data, allowing it to detect the potential fraud in credit card charges.\n",
    "\n",
    "(iii) Determining the time it would take a falling object to hit the ground: This problem can be solved without using Machine Learning. It can be solved by using classical physics formulas and mathematics for an accurate result.\n",
    "\n",
    "(iv) Determining the optimal cycle for traffic lights in a busy intersection: This problem is best suited for Machine Learning. It can be solved by using Reinforcement type of Machine Learning to determine the optimal cycle for traffic lights by using real-time data.\n",
    "\n",
    "Therefore, the answer is: [a] (ii) and (iv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\n",
    "A: represent the event of the first ball is black.\n",
    "\n",
    "B: represent the event of the second ball is black.\n",
    "\n",
    "Probability that the second ball is also black: P(B|A) = P = ?\n",
    "\n",
    "Suppose: PA is P(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA = 1/2 + 1/2 * 1/2\n",
    "PA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose: PBA is P(B ∩ A)\n",
    "\n",
    "PBA = 1/2 (when selecting the bag with 2 black balls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PBA = 1/2\n",
    "P = PBA / PA\n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the answer is: [d] 2/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.\n",
    "Suppose: PO is P(one green marble)\n",
    "Suppose: PT is P(ten green marbles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44999999999999996"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PO = 1 - 0.55\n",
    "PO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003405062891601559"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PT = PO ** 10\n",
    "PT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the answer is: $$[b] \\space 3.405 * 10^{-4}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P is the probability that (at least) one of the samples has ν = 0.\n",
    "\n",
    "P1 is the probability that there is no sample has ν = 0.\n",
    "\n",
    "P2 is the probability that ν = 0 in a sample.\n",
    "\n",
    "We have: P = 1 - P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00034050628916015635"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2 = 0.45 ** 10\n",
    "P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71136880215019"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1 = (1 - P2) ** N\n",
    "P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28863119784980995"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = 1 - P1\n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the answer is: $$[c] \\space 0.289$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.\n",
    "[a] g returns 1 for all three points.\n",
    "\n",
    "Number of target functions agreeing with hypothesis on all 3 points: 1 (111)\n",
    "\n",
    "Number of target functions agreeing with hypothesis on exactly 2 points: 3 (011, 101, 110)\n",
    "\n",
    "Number of target functions agreeing with hypothesis on exactly 1 point: 3 (001, 010, 100)\n",
    "\n",
    "=> Score = 1 x 3 + 3 x 2 + 3 x 1 = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[b] g returns 0 for all three points.\n",
    "\n",
    "Number of target functions agreeing with hypothesis on all 3 points: 1 (000)\n",
    "\n",
    "Number of target functions agreeing with hypothesis on exactly 2 points: 3 (001, 010, 100)\n",
    "\n",
    "Number of target functions agreeing with hypothesis on exactly 1 point: 3 (011, 101, 110)\n",
    "\n",
    "=> Score = 1 x 3 + 3 x 2 + 3 x 1 = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[c] g is the XOR function applied to x, i.e., if the number of 1s in x is odd, g returns 1; if it is even, g returns 0.\n",
    "\n",
    "We have: With the 3 points are 101, 110, 111, their target functions will be 0, 0, 1 respectively.\n",
    "\n",
    "Number of target functions agreeing with hypothesis on all 3 points: 1 (001)\n",
    "\n",
    "Number of target functions agreeing with hypothesis on exactly 2 points: 3 (000, 011, 101)\n",
    "\n",
    "Number of target functions agreeing with hypothesis on exactly 1 point: 3 (010, 100, 111)\n",
    "\n",
    "=> Score = 1 x 3 + 3 x 2 + 3 x 1 = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[d] g returns the opposite of the XOR function: if the number of 1s is odd, it returns 0, otherwise returns 1.\n",
    "\n",
    "We have: With the 3 points are 101, 110, 111, their target functions will be 1, 1, 0 respectively.\n",
    "\n",
    "Number of target functions agreeing with hypothesis on all 3 points: 1 (110)\n",
    "\n",
    "Number of target functions agreeing with hypothesis on exactly 2 points: 3 (010, 100, 111)\n",
    "\n",
    "Number of target functions agreeing with hypothesis on exactly 1 point: 3 (000, 011, 101)\n",
    "\n",
    "=> Score = 1 x 3 + 3 x 2 + 3 x 1 = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the answer is: [e] They are all equivalent (equal scores for g in [a] through [d])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-10. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating `target_w`, the vector of parameters of $f$ function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_target_w():\n",
    "    \"\"\"\n",
    "    Generates target_w from two random, uniformly distributed points in [-1, 1] x [-1, 1].\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    target_w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of f.\n",
    "    \"\"\"\n",
    "    # Generate two points from a uniform distribution over [-1, 1]x[-1, 1]\n",
    "    p1 = np.random.uniform(-1, 1, 2)\n",
    "    p2 = np.random.uniform(-1, 1, 2)\n",
    "    # Compute the target W from these two points\n",
    "    target_w = np.array([p1[1] * p2[0] - p1[0] * p2[1], p2[1] - p1[1], p1[0] - p2[0]]).reshape((-1, 1))\n",
    "    \n",
    "    return target_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating data set function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(N, target_w):\n",
    "    \"\"\"\n",
    "    Generates a data set by generating random inputs and then using target_w to generate the \n",
    "    corresponding outputs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        The number of examples.\n",
    "    target_w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of f.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X : numpy array, shape (N, 3)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); the first column of \n",
    "        this matrix is all ones.\n",
    "    Y : numpy array, shape (N, 1)\n",
    "        The vector of outputs.        \n",
    "    \"\"\"\n",
    "    X = np.random.uniform(-1, 1, (N, 2))\n",
    "    X = np.hstack((np.ones((N, 1)), X)) # Add 'ones' column\n",
    "    Y = np.sign(np.dot(X, target_w))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLA function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(w, x):\n",
    "    return np.sign(np.dot(x, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_converged(X, Y, w):\n",
    "    return np.array_equal(h(w, X), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_PLA(X, Y):\n",
    "    \"\"\"\n",
    "    Runs PLA.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array, shape (N, 3)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); the first column of \n",
    "        this matrix is all ones.\n",
    "    Y : numpy array, shape (N, 1)\n",
    "        The vector of outputs.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of g.\n",
    "    num_iterations : int\n",
    "        The number of iterations PLA takes to converge.\n",
    "    \"\"\"\n",
    "    w = np.zeros((X.shape[1], 1)) # Init w\n",
    "    iteration = 0\n",
    "    \n",
    "    # TODO\n",
    "\n",
    "    N = X.shape[0]\n",
    "\n",
    "    while True:\n",
    "        iteration += 1\n",
    "        mix_id = np.random.permutation(N)\n",
    "        for i in range(N):\n",
    "            xi = X[mix_id[i], :]\n",
    "            yi = Y[mix_id[i], 0]\n",
    "            if h(w, xi)[0] != yi: # misclassified point\n",
    "                w = w + (yi * xi).reshape(-1, 1)\n",
    "                iteration += 1\n",
    "\n",
    "        if has_converged(X, Y, w):\n",
    "            break\n",
    "        \n",
    "    return w, iteration\n",
    "\n",
    "# [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(N):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        The number of training examples.\n",
    "    \"\"\"\n",
    "    num_runs = 1000\n",
    "    avg_num_iterations = 0.0 # The average number of iterations PLA takes to converge\n",
    "    avg_test_err = 0.0 # The average test error of g - the final hypothesis picked by PLA\n",
    "    \n",
    "    for r in range(num_runs):\n",
    "        # Generate target_w\n",
    "        target_w = generate_target_w()\n",
    "        \n",
    "        # Generate training set\n",
    "        X, Y = generate_data(N, target_w)\n",
    "        \n",
    "        # Run PLA to pick g\n",
    "        w, num_iterations = run_PLA(X, Y)\n",
    "        \n",
    "        # Generate test set\n",
    "        X_test, Y_test = generate_data(10000, target_w)\n",
    "        \n",
    "        # Test g\n",
    "        test_err = np.mean(np.sign(np.dot(X_test, w)) != Y_test)\n",
    "        \n",
    "        # Update average values\n",
    "        avg_num_iterations += (num_iterations * 1.0 / num_runs)\n",
    "        avg_test_err += (test_err * 1.0 / num_runs)\n",
    "    \n",
    "    # Print results\n",
    "    print('avg_num_iterations = %f' % (avg_num_iterations))\n",
    "    print('avg_test_err = %f' % (avg_test_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_num_iterations = 13.724000\n",
      "avg_test_err = 0.107938\n"
     ]
    }
   ],
   "source": [
    "main(N=10) # We can use `main(10)`, but `main(N=10)` is clearer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. avg_num_iterations is closest to the answer [b] 15.\n",
    "\n",
    "8. avg_test_err is closest to the answer [c] 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_num_iterations = 134.225000\n",
      "avg_test_err = 0.013310\n"
     ]
    }
   ],
   "source": [
    "main(N=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. avg_num_iterations is closest to the answer [b] 100\n",
    "\n",
    "10. avg_test_err is closest to the answer [b] 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "   [1] Github, Florian Peter, Caltech Machine Learning Homework # 1, last commit date: 27/04/2021, access date: 31/10/2023, https://github.com/workflow/caltech-machine-learning-homework/blob/master/HW1.ipynb\n",
    "\n",
    "   [2] Tiep Vu Huu, Bài 9: Perceptron Learning Algorithm, Jan 21, 2017, access date: 31/10/2023, https://machinelearningcoban.com/2017/01/21/perceptron/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
