{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "\n",
    "Hồ Thanh Nhân - 21127122\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000 # 1000 virtual fair coins\n",
    "T = 10 # 10 times of flipping each coin independently\n",
    "M = 100000 # 100,000 times of running the experiment\n",
    "states = ['H', 'T'] # 2 states of flipping coin. Head and Tail\n",
    "coins = {}\n",
    "\n",
    "# Initialization of v_1, v_rand, v_min\n",
    "v_1_list: List[float] = []\n",
    "v_rand_list: List[float] = []\n",
    "v_min_list: List[float] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement experiment for M time(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiments(M = 1):\n",
    "    v_1: List[float] = []\n",
    "    v_rand: List[float] = []\n",
    "    v_min: List[float] = []\n",
    "    for j in range(M):\n",
    "        # Flipping 1000 virtual fair coins. Flip each coin independently 10 times.\n",
    "        coins = np.random.choice(['H', 'T'], size=(N, T))\n",
    "\n",
    "        # The first coin flipped\n",
    "        c_1 = coins[0]\n",
    "\n",
    "        # A coin chosen randomly from 1000 coins\n",
    "        c_rand = coins[np.random.randint(N)]\n",
    "\n",
    "        # c_min is the coin which had the minimum frequency of heads\n",
    "        min_head_index = np.argmin(np.sum(coins == 'H', axis = 1))\n",
    "        c_min = coins[min_head_index]\n",
    "\n",
    "        # v_1, v_rand, v_min (the fraction of heads obtained for the 3 respective coins out of the 10 tosses)\n",
    "        v_1.append(np.sum(c_1 == 'H') / T)\n",
    "        v_rand.append(np.sum(c_rand == 'H') / T)\n",
    "        v_min.append(np.sum(c_min == 'H') / T)\n",
    "\n",
    "    return v_1, v_rand, v_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the experiment 100,000 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.500233\n",
      "0.49877200000000005\n",
      "0.037691\n"
     ]
    }
   ],
   "source": [
    "v_1_list, v_rand_list, v_min_list = experiments(M)\n",
    "\n",
    "# Calculate average value for v_1, v_rand, v_min\n",
    "v_1 = np.sum(v_1_list) / M\n",
    "v_rand = np.sum(v_rand_list) / M\n",
    "v_min = np.sum(v_min_list) / M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037691"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the closest answer is [b] 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-10. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating `target_w`, the vector of parameters of $f$ function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_target_w():\n",
    "    \"\"\"\n",
    "    Generates target_w from two random, uniformly distributed points in [-1, 1] x [-1, 1].\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    target_w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of f.\n",
    "    \"\"\"\n",
    "    # Generate two points from a uniform distribution over [-1, 1]x[-1, 1]\n",
    "    p1 = np.random.uniform(-1, 1, 2)\n",
    "    p2 = np.random.uniform(-1, 1, 2)\n",
    "    # Compute the target W from these two points\n",
    "    target_w = np.array([p1[1] * p2[0] - p1[0] * p2[1], p2[1] - p1[1], p1[0] - p2[0]]).reshape((-1, 1))\n",
    "    \n",
    "    return target_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating data set function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(N, target_w):\n",
    "    \"\"\"\n",
    "    Generates a data set by generating random inputs and then using target_w to generate the \n",
    "    corresponding outputs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        The number of examples.\n",
    "    target_w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of f.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X : numpy array, shape (N, 3)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); the first column of \n",
    "        this matrix is all ones.\n",
    "    Y : numpy array, shape (N, 1)\n",
    "        The vector of outputs.        \n",
    "    \"\"\"\n",
    "    X = np.random.uniform(-1, 1, (N, 2))\n",
    "    X = np.hstack((np.ones((N, 1)), X)) # Add 'ones' column\n",
    "    Y = np.sign(np.dot(X, target_w))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLA function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_PLA(X, Y):\n",
    "    \"\"\"\n",
    "    Runs PLA.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array, shape (N, 3)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); the first column of \n",
    "        this matrix is all ones.\n",
    "    Y : numpy array, shape (N, 1)\n",
    "        The vector of outputs.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of g.\n",
    "    num_iterations : int\n",
    "        The number of iterations PLA takes to converge.\n",
    "    \"\"\"\n",
    "    w = np.zeros((X.shape[1], 1)) # Init w\n",
    "    iteration = 0\n",
    "    \n",
    "    # TODO\n",
    "    \n",
    "    return w, iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(N):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        The number of training examples.\n",
    "    \"\"\"\n",
    "    num_runs = 1000\n",
    "    avg_num_iterations = 0.0 # The average number of iterations PLA takes to converge\n",
    "    avg_test_err = 0.0 # The average test error of g - the final hypothesis picked by PLA\n",
    "    \n",
    "    for r in range(num_runs):\n",
    "        # Generate target_w\n",
    "        target_w = generate_target_w()\n",
    "        \n",
    "        # Generate training set\n",
    "        X, Y = generate_data(N, target_w)\n",
    "        \n",
    "        # Run PLA to pick g\n",
    "        w, num_iterations = run_PLA(X, Y)\n",
    "        \n",
    "        # Generate test set\n",
    "        X_test, Y_test = generate_data(10000, target_w)\n",
    "        \n",
    "        # Test g\n",
    "        test_err = np.mean(np.sign(np.dot(X_test, w)) != Y_test)\n",
    "        \n",
    "        # Update average values\n",
    "        avg_num_iterations += (num_iterations * 1.0 / num_runs)\n",
    "        avg_test_err += (test_err * 1.0 / num_runs)\n",
    "    \n",
    "    # Print results\n",
    "    print('avg_num_iterations = %f' % (avg_num_iterations))\n",
    "    print('avg_test_err = %f' % (avg_test_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_num_iterations = 0.000000\n",
      "avg_test_err = 1.000000\n"
     ]
    }
   ],
   "source": [
    "main(N=10) # We can use `main(10)`, but `main(N=10)` is clearer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Câu 7: ta thấy kết quả gần nhất với đáp án [b] 15.\n",
    "\n",
    "Câu 8: ta thấy kết quả gần nhất với đáp án [c] 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_num_iterations = 0.000000\n",
      "avg_test_err = 1.000000\n"
     ]
    }
   ],
   "source": [
    "main(N=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Câu 9: ta thấy kết quả gần nhất với đáp án ...\n",
    "\n",
    "Câu 10: ta thấy kết quả gần nhất với đáp án ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "   [1] Github, Florian Peter, Caltech Machine Learning Homework # 1, last commit date: 27/04/2021, access date: 31/10/2023, https://github.com/workflow/caltech-machine-learning-homework/blob/master/HW1.ipynb\n",
    "\n",
    "   [2] Tiep Vu Huu, Bài 9: Perceptron Learning Algorithm, Jan 21, 2017, access date: 31/10/2023, https://machinelearningcoban.com/2017/01/21/perceptron/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
